{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4590173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82ba2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3133d20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소프트 맥스 함수\n",
    "hypothesis = F.softmax(z, dim = 0)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a61a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09003057317038046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(1.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a176ec8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24472847105479767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ce1e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652409557748219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c168ad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum() # 히든 레이어에 무슨 과정이 있든 output의 합은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea51f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 손글씨\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10adc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c0b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 자료 다운\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = True,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train = False,\n",
    "                         transform = transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9bfd9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84356204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "image,label = mnist_train[0]\n",
    "print(image.shape, label) # 맨앞 1 = 흑백 / 5에 그림이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939d809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "image,label = mnist_train[4]\n",
    "print(image.shape, label) # 맨앞 1 = 흑백 / 9에 그림이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83692f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# plt.imshow(image.reshape(28, 28), cmap='gray')\n",
    "# img = np.reshape(image, [28, 28])\n",
    "# plt.imshow(img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6456b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(28*28, 10, bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504a7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d15a7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.533881009\n",
      "Epoch: 0002 cost= 0.359130800\n",
      "Epoch: 0003 cost= 0.331026435\n",
      "Epoch: 0004 cost= 0.316200465\n",
      "Epoch: 0005 cost= 0.306965530\n",
      "Epoch: 0006 cost= 0.300246567\n",
      "Epoch: 0007 cost= 0.294970453\n",
      "Epoch: 0008 cost= 0.290832430\n",
      "Epoch: 0009 cost= 0.287257314\n",
      "Epoch: 0010 cost= 0.284187764\n",
      "Epoch: 0011 cost= 0.281961352\n",
      "Epoch: 0012 cost= 0.279427111\n",
      "Epoch: 0013 cost= 0.277855515\n",
      "Epoch: 0014 cost= 0.275954545\n",
      "Epoch: 0015 cost= 0.274450421\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        y = y\n",
    "        \n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:', '%04d' %(epoch+1), 'cost=', \"{:.9f}\".format(avg_cost))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e19b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8845000267028809\n",
      "Label: 3\n",
      "Prediction: 3\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('acc:', accuracy.item())\n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:', y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "#     plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap=\"Grays\",\n",
    "#               interpolation='nearest');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68ac184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b837c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layering\n",
    "## nn.Linear(784, 10) 784 -> 10\n",
    "### 784 => 256 => 256 => 10\n",
    "linear1 = nn.Linear(784, 256, bias=True)\n",
    "linear2 = nn.Linear(256, 256, bias=True)\n",
    "linear3 = nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f30374ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.6893, -0.4671,  0.5253,  ..., -0.0257,  0.2940, -0.2990],\n",
       "        [-0.5818, -2.3138, -0.1847,  ..., -0.2662, -0.1162, -0.2116],\n",
       "        [-0.2966, -0.4684, -1.8893,  ..., -1.2298,  0.5110,  1.5660],\n",
       "        ...,\n",
       "        [ 1.6858, -1.0401,  0.3106,  ...,  0.9472, -0.4404, -0.1522],\n",
       "        [-0.8159,  0.7047,  0.4257,  ..., -0.5285,  0.8930,  0.0655],\n",
       "        [ 1.8216,  0.3508, -0.6248,  ...,  0.0724, -0.5328,  1.1339]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(linear1.weight)\n",
    "nn.init.normal_(linear2.weight)\n",
    "nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe6e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1,relu, linear2, relu, linear3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa0f3ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.722817540\n",
      "Epoch: 0002 cost= 0.517449379\n",
      "Epoch: 0003 cost= 0.412883133\n",
      "Epoch: 0004 cost= 0.416101992\n",
      "Epoch: 0005 cost= 0.379029304\n",
      "Epoch: 0006 cost= 0.326235890\n",
      "Epoch: 0007 cost= 0.290790617\n",
      "Epoch: 0008 cost= 0.272243381\n",
      "Epoch: 0009 cost= 0.322498947\n",
      "Epoch: 0010 cost= 0.284422606\n",
      "Epoch: 0011 cost= 0.187442034\n",
      "Epoch: 0012 cost= 0.282492965\n",
      "Epoch: 0013 cost= 0.272864014\n",
      "Epoch: 0014 cost= 0.197593585\n",
      "Epoch: 0015 cost= 0.147219941\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "total_batch = len(data_loader)\n",
    "train_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    avg_cost = 0\n",
    "    for X, y in data_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        y = y\n",
    "        optimizer.zero_grad()\n",
    "        hyp = model(X)\n",
    "        cost = criterion(hyp, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=cost/total_batch\n",
    "    print('Epoch:', \"%04d\"%(epoch+1), 'cost=', '{:0.9f}'.format(avg_cost))\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea2078f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8845000267028809\n",
      "Label: 7\n",
      "Prediction: 7\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('acc:', accuracy.item())\n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:', y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "#     plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap=\"Grays\",\n",
    "#               interpolation='nearest');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
